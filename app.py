import os
import streamlit as st
import google.generativeai as genai

st.set_page_config(page_title="è¨­å®šè¦‹ç›´ã—ï¼†å†èµ·å‹•ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", page_icon="ğŸ› ï¸")
st.title("ğŸ› ï¸ è¨­å®šè¦‹ç›´ã—ï¼†å†èµ·å‹•ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.caption("Gemini API ã§å‹•ãã‚·ãƒ³ãƒ—ãƒ«ãªã‚µãƒãƒ¼ãƒˆBot / æ—¢å®šã®å¯¾å‡¦: è¨­å®šè¦‹ç›´ã— â†’ å†èµ·å‹•")

# --- API ã‚­ãƒ¼ã®å–å¾—ï¼ˆStreamlit Secrets ã¾ãŸã¯ ç’°å¢ƒå¤‰æ•° â†’ æœªè¨­å®šãªã‚‰å…¥åŠ›æ¬„ï¼‰ ---
api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY", ""))
if not api_key:
    with st.expander("åˆå›è¨­å®š: GEMINI_API_KEY ã‚’å…¥åŠ› (ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã¿ä¿æŒ)"):
        api_key = st.text_input("GEMINI_API_KEY", type="password")
if not api_key:
    st.stop()

# --- Gemini åˆæœŸåŒ– ---
genai.configure(api_key=api_key)
model = genai.GenerativeModel("models/gemini-2.5-flash")

SYSTEM_PROMPT = (
    "ã‚ãªãŸã¯æ—¥æœ¬èªã®ã‚µãƒãƒ¼ãƒˆãƒœãƒƒãƒˆã§ã™ã€‚æ–¹é‡:\n"
    "- ã¾ãšã€è¨­å®šã®è¦‹ç›´ã—ã€ã¨ã€å†èµ·å‹•ã€ã‚’åŸºæœ¬ã®å¯¾å‡¦ã¨ã—ã¦æ¡ˆå†…ã™ã‚‹ã€‚\n"
    "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€ã‚‚ã†ã‚„ã£ãŸ/åŠ¹æœãªã—ã€ã¨è¨€ã£ãŸã‚‰ã€ç°¡å˜ãªç¢ºèªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ â†’ è¿½åŠ ã®è»½ã„å¯¾å‡¦ï¼ˆãƒ­ã‚°ã‚¢ã‚¦ãƒˆ/ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤/ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆç¢ºèªãªã©ï¼‰â†’ ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆçª“å£/ãƒ­ã‚°å…±æœ‰ï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚\n"
    "- å›ç­”ã¯3ã€œ6è¡Œã§ç°¡æ½”ã«ã€æ‰‹é †ã¯ç•ªå·ä»˜ãã€‚å°‚é–€ç”¨èªã¯å™›ã¿ç •ãã€‚å±é™ºãªä½œæ¥­ã¯å‹§ã‚ãªã„ã€‚\n"
    "- ä¸æ˜ç‚¹ã¯1å•ã ã‘ç¢ºèªè³ªå•ã‚’è¿”ã™ï¼ˆä¾‹: ã©ã®ã‚¢ãƒ—ãƒª/ç«¯æœ«ã‹ï¼‰ã€‚å€‹äººæƒ…å ±ã¯åé›†ã—ãªã„ã€‚\n"
)

# --- ç°¡æ˜“ãƒãƒ£ãƒƒãƒˆUI ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

if not st.session_state.messages:
    with st.chat_message("assistant"):
        st.write("å›°ã£ã¦ã„ã‚‹å†…å®¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ã¾ãšã¯ **è¨­å®šã®è¦‹ç›´ã— â†’ å†èµ·å‹•** ã‹ã‚‰ã”æ¡ˆå†…ã—ã¾ã™ã€‚")

user_msg = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›â€¦")
if user_msg:
    st.session_state.messages.append({"role": "user", "content": user_msg})
    with st.chat_message("user"):
        st.markdown(user_msg)

    # --- ç›´è¿‘å±¥æ­´ã‚’ã¾ã¨ã‚ã¦ Gemini ã«æŠ•ã’ã‚‹ï¼ˆæœ€å°å®Ÿè£…ï¼‰ ---
    history_text = "\n\n".join(
        [
            ("ãƒ¦ãƒ¼ã‚¶ãƒ¼: " + m["content"]) if m["role"] == "user" else ("ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: " + m["content"])
            for m in st.session_state.messages[-8:]
        ]
    )
    prompt = (
        f"{SYSTEM_PROMPT}\n\nã“ã‚Œã¾ã§ã®ä¼šè©±:\n{history_text}\n\n"
        "æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ã€ä¸Šè¨˜æ–¹é‡ã«å³å¯†ã«å¾“ã£ã¦æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    )

    try:
        resp = model.generate_content(prompt)
        text = (resp.text or "") if hasattr(resp, "text") else ""
        if not text:
            text = "ï¼ˆå¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ï¼‰"
    except Exception as e:
        text = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

    st.session_state.messages.append({"role": "assistant", "content": text})
    with st.chat_message("assistant"):
        st.markdown(text)

st.divider()
st.caption("ã“ã®Botã¯ä¸€èˆ¬çš„ãªã‚¬ã‚¤ãƒ‰ã§ã™ã€‚é‡è¦ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚„å±é™ºãªæ“ä½œã¯å®Ÿæ–½ã›ãšã€å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç¢ºèªã‚„æ‹…å½“çª“å£ã¸ã®é€£çµ¡ã‚‚ä½µç”¨ã—ã¦ãã ã•ã„ã€‚")